{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy\n",
    "!pip install chromadb langchain langchain-community\n",
    "!pip install peft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuning embedding model using LoRA and triplet loss\n",
    "    - Prepare Data - Triplet Datasets\n",
    "        - Anchor/Query: Product to find similar items for\n",
    "        - Positive: Represents a similar product\n",
    "        - Negative: Represents a disimilar product\n",
    "    - Choose Model : Capable of producing high quality vector representations\n",
    "        - Siamese Networks(Twin Networks): These networks have two branches that process inputs (anchor and positive/negative) and output embeddings that are compared using a loss function.\n",
    "        - Sentence Transformers: Designed for semantic similarity tasks, these models can learn embeddings for text(product descriptions, titles)\n",
    "    - Train with triplet loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>product_type</th>\n",
       "      <th>country</th>\n",
       "      <th>enhanced_product_desc</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_caption</th>\n",
       "      <th>complete_product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07TG4V6BV</td>\n",
       "      <td>Amazon Brand - Solimo Designer Black and White...</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>IN</td>\n",
       "      <td>Given Product description: , No Warranty, bran...</td>\n",
       "      <td>5f/5f39a379.jpg</td>\n",
       "      <td>a black and white phone case with a design on it</td>\n",
       "      <td>a black and white phone case with a design on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B07T2K5MY1</td>\n",
       "      <td>Amazon Brand - Solimo Designer Galaxy 3D Print...</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>IN</td>\n",
       "      <td>Given Product description: , No Warranty, bran...</td>\n",
       "      <td>4a/4ab3ead6.jpg</td>\n",
       "      <td>a phone case with an orange swirl design</td>\n",
       "      <td>a phone case with an orange swirl design Given...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0854LLTNR</td>\n",
       "      <td>Amazon Brand - Solimo Designer Daddy's Girl an...</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>IN</td>\n",
       "      <td>Given Product description: , Extreme precision...</td>\n",
       "      <td>cd/cd678bbf.jpg</td>\n",
       "      <td>a black and white phone case with the words da...</td>\n",
       "      <td>a black and white phone case with the words da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B07TGBPM1H</td>\n",
       "      <td>Amazon Brand - Solimo Designer Kiss-ing Couple...</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>IN</td>\n",
       "      <td>Given Product description: , None, brand: Amaz...</td>\n",
       "      <td>d4/d47d521f.jpg</td>\n",
       "      <td>a couple is silhouetted against each other pho...</td>\n",
       "      <td>a couple is silhouetted against each other pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B077VJDKLV</td>\n",
       "      <td>find. Women’s Flat Mule Sandals, Black, 8 UK</td>\n",
       "      <td>SANDAL</td>\n",
       "      <td>GB</td>\n",
       "      <td>Given Product description: , Leather look uppe...</td>\n",
       "      <td>8e/8e2b2da0.jpg</td>\n",
       "      <td>a pair of black sandals on a white background</td>\n",
       "      <td>a pair of black sandals on a white background ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                          item_name  \\\n",
       "0  B07TG4V6BV  Amazon Brand - Solimo Designer Black and White...   \n",
       "1  B07T2K5MY1  Amazon Brand - Solimo Designer Galaxy 3D Print...   \n",
       "2  B0854LLTNR  Amazon Brand - Solimo Designer Daddy's Girl an...   \n",
       "3  B07TGBPM1H  Amazon Brand - Solimo Designer Kiss-ing Couple...   \n",
       "4  B077VJDKLV       find. Women’s Flat Mule Sandals, Black, 8 UK   \n",
       "\n",
       "          product_type country  \\\n",
       "0  CELLULAR_PHONE_CASE      IN   \n",
       "1  CELLULAR_PHONE_CASE      IN   \n",
       "2  CELLULAR_PHONE_CASE      IN   \n",
       "3  CELLULAR_PHONE_CASE      IN   \n",
       "4               SANDAL      GB   \n",
       "\n",
       "                               enhanced_product_desc       image_path  \\\n",
       "0  Given Product description: , No Warranty, bran...  5f/5f39a379.jpg   \n",
       "1  Given Product description: , No Warranty, bran...  4a/4ab3ead6.jpg   \n",
       "2  Given Product description: , Extreme precision...  cd/cd678bbf.jpg   \n",
       "3  Given Product description: , None, brand: Amaz...  d4/d47d521f.jpg   \n",
       "4  Given Product description: , Leather look uppe...  8e/8e2b2da0.jpg   \n",
       "\n",
       "                                       image_caption  \\\n",
       "0   a black and white phone case with a design on it   \n",
       "1           a phone case with an orange swirl design   \n",
       "2  a black and white phone case with the words da...   \n",
       "3  a couple is silhouetted against each other pho...   \n",
       "4      a pair of black sandals on a white background   \n",
       "\n",
       "                        complete_product_description  \n",
       "0  a black and white phone case with a design on ...  \n",
       "1  a phone case with an orange swirl design Given...  \n",
       "2  a black and white phone case with the words da...  \n",
       "3  a couple is silhouetted against each other pho...  \n",
       "4  a pair of black sandals on a white background ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df_master = pd.read_csv(\"sample_20k.csv\")\n",
    "df_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CELLULAR_PHONE_CASE' 'SANDAL' 'SHOES' 'OUTDOOR_LIVING'\n",
      " 'HEALTH_PERSONAL_CARE' 'GPS_OR_NAVIGATION_ACCESSORY' 'GROCERY' 'HERB'\n",
      " 'BEAUTY' 'CHAIR' 'NUTRITIONAL_SUPPLEMENT' 'KITCHEN' 'JANITORIAL_SUPPLY'\n",
      " 'ABIS_DRUGSTORE' 'EARRING' 'HOME_BED_AND_BATH' 'BACKPACK' 'LAMP' 'HOME'\n",
      " 'HANDBAG' 'HARDWARE_HANDLE' 'SAUTE_FRY_PAN' 'FINENECKLACEBRACELETANKLET'\n",
      " 'HOME_LIGHTING_AND_LAMPS' 'NECKLACE' 'TABLE' 'PET_SUPPLIES'\n",
      " 'ELECTRIC_FAN' 'SCISSORS' 'WATCH' 'COFFEE' 'WRITING_BOARD' 'SNACK_MIX'\n",
      " 'SKIN_FOUNDATION_CONCEALER' 'SOFA' 'HEADBOARD' 'AUTO_ACCESSORY'\n",
      " 'DISHWASHER_DETERGENT' 'OFFICE_PRODUCTS' 'SLOW_COOKER'\n",
      " 'HOME_FURNITURE_AND_DECOR' 'FURNITURE' 'SCREEN_PROTECTOR' 'RUG'\n",
      " 'NUT_BUTTER' 'PILLOW' 'BOOT' 'VITAMIN' 'CHARGING_ADAPTER'\n",
      " 'WIRELESS_ACCESSORY' 'LIGHT_BULB' 'HAT' 'MASCARA' 'AV_FURNITURE' 'CLOCK'\n",
      " 'WASTE_BAG' 'SKIN_CLEANING_AGENT' 'ACCESSORY' 'SUITCASE' 'WALL_ART'\n",
      " 'SUNSCREEN' 'ELECTRONIC_ADAPTER' 'BABY_BOTTLE' 'BABY_PRODUCT'\n",
      " 'MILK_SUBSTITUTE' 'BED_FRAME' 'DRINKING_CUP' 'WALLET' 'SHELF'\n",
      " 'COMPUTER_COMPONENT' 'MULTIPORT_HUB' 'FINERING' 'BAKING_PAN'\n",
      " 'HERBAL_SUPPLEMENT' 'BENCH' 'UMBRELLA' 'CAMERA_TRIPOD' 'SAFETY_SUPPLY'\n",
      " 'OTTOMAN' 'BREAD' 'BOTTLE_RACK' 'BATTERY' 'COMPUTER_DRIVE_OR_STORAGE'\n",
      " 'ACCESSORY_OR_PART_OR_SUPPLY' 'FLAT_SHEET' 'LIGHT_FIXTURE' 'PLANTER'\n",
      " 'SKIN_CLEANING_WIPE' 'SPORTING_GOODS' 'LUGGAGE' 'FACIAL_TISSUE'\n",
      " 'FINEEARRING' 'PORTABLE_AV_DEVICE' 'JAR' 'SKIN_MOISTURIZER'\n",
      " 'FOOD_SERVICE_SUPPLY' 'FREESTANDING_SHELTER' 'INK_OR_TONER'\n",
      " 'AIR_CONDITIONER' 'BISS' 'MAJOR_HOME_APPLIANCES' 'CLOTHES_RACK'\n",
      " 'ORTHOPEDIC_BRACE' 'DRESSER' 'RING' 'TEA' 'CARGO_STRAP' 'DESK'\n",
      " 'SALAD_DRESSING' 'SWATCH' 'EDIBLE_OIL_VEGETABLE'\n",
      " 'INSTRUMENT_PARTS_AND_ACCESSORIES' 'FLAT_SCREEN_DISPLAY_MOUNT' 'TOOLS'\n",
      " 'STRING_LIGHT' 'BRACELET' 'TECHNICAL_SPORT_SHOE' 'DISHWARE_PLACE_SETTING'\n",
      " 'NOODLE' 'BED' 'HEADPHONES' 'SUGAR' 'PROTEIN_SUPPLEMENT_POWDER' 'HONEY'\n",
      " 'OUTDOOR_RECREATION_PRODUCT' 'FRUIT' 'TOWEL_HOLDER' 'PAPER_PRODUCT'\n",
      " 'BASKET' 'MARKING_PEN' 'FURNITURE_COVER' 'LEGUME' 'ANIMAL_LITTER'\n",
      " 'STORAGE_BINDER' 'WILDLIFE_FEEDER' 'AUTO_PART' 'ABIS_HOME_IMPROVEMENT'\n",
      " 'LABEL' 'SEALS' 'RECREATION_BALL' 'STORAGE_BAG' 'SHAMPOO'\n",
      " 'PRINT_COPY_PAPER' 'CLEANING_AGENT' 'CAR_AUDIO_OR_THEATER'\n",
      " 'DAIRY_BASED_DRINK' 'OFFICE_ELECTRONICS' 'ABIS_BEAUTY' 'STORAGE_HOOK'\n",
      " 'NUTS' 'WATER' 'CAMERA_SUPPORT' 'STORAGE_BOX' 'ABIS_LAWN_AND_GARDEN'\n",
      " 'VASE' 'LEAVENING_AGENT' 'BODY_POSITIONER' 'WINE' 'CANDLE' 'POWER_BANK'\n",
      " 'INCENSE' 'MEDICATION' 'AREA_DEODORIZER' 'PLUMBING_FIXTURE'\n",
      " 'TEACHING_EQUIPMENT' 'TOILET_SEAT' 'STOOL_SEATING'\n",
      " 'THERMOPLASTIC_FILAMENT' 'DRINK_FLAVORED' 'DAIRY_BASED_CREAM'\n",
      " 'CUTTING_BOARD' 'COMPUTER_ADD_ON' 'SKIN_EXFOLIANT' 'COSMETIC_CASE'\n",
      " 'DAIRY_BASED_BUTTER' 'HOME_MIRROR' 'HARDWARE' 'JEWELRY_SET' 'FLATWARE'\n",
      " 'VEGETABLE' 'ENVELOPE' 'SHOE_INSERT' 'DRYING_RACK' 'SNACK_CHIP_AND_CRISP'\n",
      " 'ANTENNA' 'DAIRY_BASED_ICE_CREAM' 'CONSUMER_ELECTRONICS'\n",
      " 'POWER_SUPPLIES_OR_PROTECTION' 'TRASH_CAN' 'COOKIE' 'SAFETY_GLASSES'\n",
      " 'CABINET' 'VIDEO_GAME_ACCESSORIES' 'SUNGLASSES' 'FINEOTHER'\n",
      " 'PORTABLE_ELECTRONIC_DEVICE_COVER' 'COOKING_OVEN'\n",
      " 'HOME_LIGHTING_ACCESSORY' 'DAIRY_BASED_CHEESE' 'MOUTHWASH'\n",
      " 'PERSONAL_CARE_APPLIANCE' 'JERKY' 'LEOTARD' 'PLACEMAT' 'REFRIGERATOR'\n",
      " 'DUTCH_OVENS' 'MATTRESS' 'PERSONAL_COMPUTER' 'REMOTE_CONTROL' 'CAKE'\n",
      " 'MECHANICAL_COMPONENTS' 'WRITING_INSTRUMENT' 'MINERAL_SUPPLEMENT'\n",
      " 'HARDWARE_HINGE' 'PORTABLE_ELECTRONIC_DEVICE_MOUNT' 'SAFE' 'CE_ACCESSORY'\n",
      " 'CONDITIONER' 'BREAKFAST_CEREAL' 'FILE_FOLDER' 'LOCK'\n",
      " 'PERCUSSION_INSTRUMENTS' 'TOY_FIGURE' 'SAUCE' 'FAUCET'\n",
      " 'BATHWATER_ADDITIVE' 'PUMP_DISPENSER' 'BAKING_PAPER' 'VINEGAR'\n",
      " 'CHILDRENS_COSTUME' 'COMPUTER' 'CLOTHES_HANGER' 'FOOD_STORAGE_BAG'\n",
      " 'PAPER_TOWEL_HOLDER' 'AUTO_OIL' 'CANDY' 'PLIERS' 'LAUNDRY_DETERGENT'\n",
      " 'SCREWDRIVER' 'TOILET_PAPER_HOLDER' 'BROOM'\n",
      " 'FASHIONNECKLACEBRACELETANKLET' 'PACKAGED_SOUP_AND_STEW' 'FOUNTAIN'\n",
      " 'PHONE_ACCESSORY' 'CANDLE_HOLDER' 'FOOD_BLENDER' 'BEAN_BAG_CHAIR'\n",
      " 'FRUIT_SNACK' 'FLAVORED_DRINK_CONCENTRATE' 'BUILDING_MATERIAL'\n",
      " 'FASHIONEARRING' 'STICKER_DECAL' 'SHIPPING_BOX' 'BAG' 'DRILL' 'PET_TOY'\n",
      " 'SECURITY_ELECTRONICS' 'MEAL_HOLDER' 'KITCHEN_KNIFE' 'WRENCH'\n",
      " 'FLASH_MEMORY' 'BOTTLE' 'EXERCISE_MAT' 'DISHWARE_PLATE' 'INPUT_MOUSE'\n",
      " 'PICTURE_FRAME' 'COMPUTER_INPUT_DEVICE' 'COMPUTER_SPEAKER' 'EARMUFF'\n",
      " 'MEAT' 'SALWAR_SUIT_SET' 'AIR_PURIFIER' 'BREAD_MAKING_MACHINE'\n",
      " 'SNACK_FOOD_BAR' 'CARRYING_CASE_OR_BAG' 'POWER_STRIP' 'SHOWERHEAD'\n",
      " 'SELF_STICK_NOTE' 'BAKING_MIX' 'FOOD_PROCESSOR' 'DRILL_BITS'\n",
      " 'STORAGE_RACK' 'INPUT_PEN' 'PANTRY' 'FASHIONRING' 'ICE_CHEST'\n",
      " 'ELECTRONIC_SWITCH' 'POULTRY' 'TABLETOP_GAME' 'RAZOR_BLADE_CARTRIDGE'\n",
      " 'FLOUR' 'PORTABLE_AUDIO' 'WINDOW_SHADE' 'WOUND_DRESSING'\n",
      " 'CAMERA_OTHER_ACCESSORIES' 'MUSCLE_ROLLER' 'TOY_SLIME' 'KEYBOARDS'\n",
      " 'JUICE_AND_JUICE_DRINK' 'PASTRY' 'DRINK_COASTER' 'SUGAR_SUBSTITUTE'\n",
      " 'POT_HOLDER' 'TOOTHBRUSH_HOLDER' 'STAPLER' 'CARD_STOCK' 'CLEANING_BRUSH'\n",
      " 'HAIR_IRON' 'TOASTER' 'CE_CARRYING_CASE_OR_BAG' 'COUNTERTOP_BURNER'\n",
      " 'COMPUTER_COOLING_DEVICE' 'RADIO' 'CAN_OPENER' 'HAIR_COLORING_AGENT'\n",
      " 'BLANK_MEDIA' 'LICENSE_PLATE_ATTACHMENT' 'WATER_PURIFICATION_UNIT'\n",
      " 'PROFESSIONAL_HEALTHCARE' 'AUDIO_OR_VIDEO' 'SPEAKERS'\n",
      " 'VEHICLE_LIGHT_BULB' 'MASSAGER' 'CURTAIN' 'RUG_PAD' 'DEHUMIDIFIER'\n",
      " 'COSMETIC_BRUSH' 'ART_AND_CRAFT_SUPPLY' 'ASTRINGENT_SUBSTANCE' 'CRACKER'\n",
      " 'VACUUM_CLEANER' 'VEHICLE_INTERIOR_SHADE' 'LIP_COLOR' 'LAUNDRY_HAMPER'\n",
      " 'EARPLUG' 'TELEVISION' 'FLASH_DRIVE' 'MICROSCOPES' 'BOXING_GLOVE'\n",
      " 'ELECTRIC_WATER_BOILER' 'CAMERA_LENS_FILTERS' 'EYEWEAR' 'TENT'\n",
      " 'SWEATBAND' 'WASHER_DRYER_COMBINATION' 'EXERCISE_BAND' 'LADDER'\n",
      " 'LAUNDRY_APPLIANCE' 'PORTABLE_STOVE' 'DISHWARE_BOWL' 'PRETZEL' 'FISH'\n",
      " 'SHEET_PAN' 'COFFEE_MAKER' 'CADDY' 'MOUSE_PAD' 'EDUCATIONAL_SUPPLIES'\n",
      " 'PRESSURE_COOKER' 'STEERING_WHEEL_COVER' 'TOTE_BAG'\n",
      " 'SOUND_AND_RECORDING_EQUIPMENT' 'TOYS_AND_GAMES'\n",
      " 'PORTABLE_ELECTRONIC_DEVICE_STAND' 'BAKING_CUP' 'SLEEP_MASK'\n",
      " 'EYELID_COLOR' 'ICE_CUBE_TRAY' 'DOORSTOP' 'PITCHER' 'NAIL_POLISH'\n",
      " 'SYSTEM_POWER_DEVICE' 'FASHIONOTHER' 'WHEEL' 'CAMERA_BAGS_AND_CASES'\n",
      " 'DRINKING_STRAW' 'CAMCORDER' 'DIGITAL_DEVICE_3' 'HAIRBAND' 'HUMIDIFIER'\n",
      " 'HAIR_STYLING_AGENT' 'UTILITY_KNIFE' 'BARBECUE_GRILL' 'TOOTHBRUSH'\n",
      " 'AIR_MATTRESS' 'RICE_COOKERS' 'GUITARS']\n",
      "387\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE_SIZE = 500\n",
    "# df_tune_sample = df_master.sample(SAMPLE_SIZE)\n",
    "# df_tune_sample.head()\n",
    "\n",
    "df_tune_sample = df_master.copy()\n",
    "\n",
    "print(df_tune_sample['product_type'].unique())\n",
    "print(df_tune_sample['product_type'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Data Preparation: Load and format triplet dataset\n",
    "\n",
    "## 2. Model Selection\n",
    "\n",
    "## 3. Training with Triplet Loss\n",
    "#     - Define Loss Function (e.g., TripletMarginLoss)\n",
    "#     - Training Loop\n",
    "#     - Calculate Loss\n",
    "#     - Backpropagate\n",
    "#     - Update Weights\n",
    "\n",
    "## 4. Evaluation and Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Preparation: Load and format triplet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Data Preparation: Load and format triplet dataset\n",
    "\n",
    "import random\n",
    "\n",
    "# Category groups - ensure each has enough samples.\n",
    "category_groups = df_tune_sample.groupby('product_type')\n",
    "\n",
    "# Create triplet samples\n",
    "triplets = []\n",
    "for category, group in category_groups:\n",
    "    group_list = group.to_dict(\"records\")\n",
    "\n",
    "    for anchor in group_list:\n",
    "        # Select a positive sample from the same caregory\n",
    "        positive = random.choice(group_list)\n",
    "\n",
    "        # Select a negative sample from a different category\n",
    "        while True:\n",
    "            negative_category = random.choice(df_tune_sample[\"product_type\"].unique())\n",
    "            if negative_category != category:\n",
    "                negative = df_tune_sample[df_tune_sample[\"product_type\"] == negative_category].sample(1).to_dict(\"records\")[0]\n",
    "                break\n",
    "\n",
    "        triplets.append((anchor[\"item_name\"], positive[\"complete_product_description\"], negative[\"complete_product_description\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitilroy/Dev/src/capstone/master/ShopTalk/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load Pre-Trained Model\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Apply LoRA configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 73,728 || all params: 22,786,944 || trainable%: 0.3236\n"
     ]
    }
   ],
   "source": [
    "# Apply LoRA for efficient fine-tuning. It will adapt only selected layers\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.FEATURE_EXTRACTION, # We will extract embeddings\n",
    "    inference_mode= False,\n",
    "    r=8, # Low-rank dimension\n",
    "    lora_alpha=32, # Scaling factor\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# Wrap the model with LoRA\n",
    "peft_model = get_peft_model(base_model, config)\n",
    "peft_model.print_trainable_parameters() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create Triplet Loss Dataset\n",
    "Tokenize anchor, positive and negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ProductTripletDataset(Dataset):\n",
    "    def __init__(self, triplets, tokenizer):\n",
    "        self.triplets = triplets\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor, positive, negative = self.triplets[idx]\n",
    "\n",
    "        anchor_input = self.tokenizer(anchor, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "        positive_input = self.tokenizer(positive, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "        negative_input = self.tokenizer(negative, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "\n",
    "        return {\n",
    "            \"anchor\": anchor_input,\n",
    "            \"positive\": positive_input,\n",
    "            \"negative\": negative_input\n",
    "        }\n",
    "\n",
    "train_dataset = ProductTripletDataset(triplets, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Define Training Loop with Triplet Loss\n",
    "Triplet loss ensure achor-positive pairs are closer than anchor-negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    device = torch.device(\"cpu\")\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    print(\"Device: \", device)\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  mps\n",
      "Epoch 1, Loss: 0.07783677551150323\n",
      "Epoch 2, Loss: 0.0347711225271225\n",
      "Epoch 3, Loss: 0.027800049084424974\n",
      "Epoch 4, Loss: 0.02388069538474083\n",
      "Epoch 5, Loss: 0.0220460361123085\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import TripletMarginLoss\n",
    "\n",
    "device = get_device()\n",
    "peft_model.to(device)\n",
    "# Ensure model weights are in float32 on MPS\n",
    "if device.type == \"mps\":\n",
    "    peft_model = peft_model.to(torch.float32)\n",
    "\n",
    "optimizer = optim.AdamW(peft_model.parameters(), lr = 5e-5)\n",
    "loss_fn = TripletMarginLoss(margin=0.5) # Margin controls separation\n",
    "\n",
    "#Training Loop\n",
    "for epoch in range(5):\n",
    "    peft_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move inputs to device for MPS\n",
    "\n",
    "        # Ensure input tensors are moved to the correct device and dtype\n",
    "        # if device.type == \"cuda\":\n",
    "        #     inputs = {k: v.to(device, dtype=torch.float16) for k, v in inputs.items()}  # Use float16 for CUDA (if needed)\n",
    "        # else: # MPS or CPU\n",
    "        #     inputs = {k: v.to(device, dtype=torch.float32) for k, v in inputs.items()}  # Use float32 for MPS and CPU\n",
    "\n",
    "        anchor_inputs = {key: value.squeeze().to(device, dtype=torch.long) for key, value in batch[\"anchor\"].items()}\n",
    "        positive_inputs = {key: value.squeeze().to(device, dtype=torch.long)for key, value in batch[\"positive\"].items()}\n",
    "        negative_inputs = {key: value.squeeze().to(device, dtype=torch.long) for key, value in batch[\"negative\"].items()}\n",
    "\n",
    "        # Get embeddings\n",
    "        anchor_embed = peft_model(**anchor_inputs).pooler_output\n",
    "        positive_embed = peft_model(**positive_inputs).pooler_output\n",
    "        negative_embed = peft_model(**negative_inputs).pooler_output\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(anchor_embed, positive_embed, negative_embed)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Save Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fine_tuned_lora_tripletloss/tokenizer_config.json',\n",
       " 'fine_tuned_lora_tripletloss/special_tokens_map.json',\n",
       " 'fine_tuned_lora_tripletloss/vocab.txt',\n",
       " 'fine_tuned_lora_tripletloss/added_tokens.json',\n",
       " 'fine_tuned_lora_tripletloss/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save fine-tuned model\n",
    "peft_model.save_pretrained(\"fine_tuned_lora_tripletloss\")\n",
    "peft_model.base_model.save_pretrained(\"fine_tuned_lora_tripletloss\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_lora_tripletloss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Load Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT Model and Tokenizer Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "saved_model_path = \"fine_tuned_lora_tripletloss\"\n",
    "base_model = AutoModel.from_pretrained(saved_model_path)\n",
    "# Load the PEFT model (adapter) on top of the base model\n",
    "peft_model = PeftModel.from_pretrained(base_model, saved_model_path)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "peft_model = peft_model.to(device)\n",
    "\n",
    "# Ensure model weights are in float32 on MPS\n",
    "if device.type == \"mps\":\n",
    "    peft_model = peft_model.to(torch.float32)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
    "\n",
    "# Ensure tokenizer is prepared correctly\n",
    "# Set the padding token if not available\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token (if available)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})  # Add a new pad token if eos_token is also missing\n",
    "\n",
    "print(\"PEFT Model and Tokenizer Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create Custom Function and Class for Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "#### Compute Embeddings for all products\n",
    "def custom_embedding_function(text):\n",
    "    #print(f\"Embedding text: '{text[:50]}...'\")  # Debug: Check if function is called\n",
    "    \"\"\"Compute embedding using fine-tuned LoRA model.\"\"\"\n",
    "    tokenized = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "\n",
    "    # Move tokenized input to the same device as the model\n",
    "    tokenized = {key: value.to(device, dtype=torch.long) for key, value in tokenized.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass through the model (on the correct device)\n",
    "        outputs = peft_model(**tokenized)\n",
    "        #print(f\"Type of outputs: {type(outputs)}\") #debug\n",
    "        #print(f\"Outputs keys: {getattr(outputs, 'keys', lambda: None)()}\") #debug\n",
    "        #print(f\"Outputs shape: {getattr(outputs, 'shape', lambda: None)}\") #debug\n",
    "        if hasattr(outputs, \"pooler_output\"):\n",
    "            embeddings = outputs.pooler_output.cpu().numpy().tolist()[0]\n",
    "        elif hasattr(outputs, \"last_hidden_state\"):\n",
    "            # Mean pooling\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy().tolist()[0]\n",
    "            #OR CLS token extraction\n",
    "            #embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy().tolist()[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected output structure: {type(outputs)}\")\n",
    "        \n",
    "    #print(f\"Embedding length: {len(embeddings)}, Type: {type(embeddings)}\") #debug\n",
    "    return embeddings\n",
    "\n",
    "# --- Custom Embedding Class ---\n",
    "class LoRAEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        print(f\"Number of texts to embed: {len(texts)}\")  # Debug: Check number of texts\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            embeddings.append(custom_embedding_function(text))\n",
    "        print(f\"Number of embeddings created: {len(embeddings)}\")  # Debug: Check number of embeddings\n",
    "        return embeddings\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        return custom_embedding_function(text) #use same embedding function for query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Generate Embeddings, Save to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of texts before Chroma: 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y4/z3s1vk012bv7p_188zpx6w3c0000gn/T/ipykernel_15312/3217206501.py:27: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(embedding_function=embeddings, persist_directory=PERSIST_DIRECTORY)  # Pass embeddings to Chroma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts to embed: 20000\n",
      "Number of embeddings created: 20000\n",
      "✅ Embeddings saved successfully from DataFrame to chromadb_vectorstore_lora!\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame rows into embeddings and store them\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "PERSIST_DIRECTORY = \"chromadb_vectorstore_lora\"\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "embeddings = []\n",
    "\n",
    "for _, row in df_tune_sample.iterrows():\n",
    "    text = row[\"complete_product_description\"]  # Product description\n",
    "    \n",
    "    texts.append(text)\n",
    "    metadatas.append({\"id\": str(row[\"item_id\"]),\n",
    "                      \"name\": row[\"item_name\"],\n",
    "                      \"category\": row[\"product_type\"],\n",
    "                      \"country\": row[\"country\"],\n",
    "                      \"image_path\": row[\"image_path\"]})\n",
    "\n",
    "# Store all embeddings in ChromaDB\n",
    "# vector_store.add_texts(texts=texts, metadatas=metadatas)\n",
    "\n",
    "print(f\"Length of texts before Chroma: {len(texts)}\") #debug\n",
    "\n",
    "# Initialize your custom embedding class\n",
    "embeddings = LoRAEmbeddings()\n",
    "vectorstore = Chroma(embedding_function=embeddings, persist_directory=PERSIST_DIRECTORY)  # Pass embeddings to Chroma\n",
    "\n",
    "# Initialize Chroma with the embedding object\n",
    "vectorstore.add_texts(texts=texts, embedding=embeddings, metadatas=metadatas)\n",
    "\n",
    "print(f\"✅ Embeddings saved successfully from DataFrame to {PERSIST_DIRECTORY}!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10: Load Vector Store, Retrieve Top-k Similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your custom embedding class\n",
    "embeddings = LoRAEmbeddings()\n",
    "vectorstore = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: a colorful phone case for the iphone Given Product description: , No Warranty, brand: Amazon Brand - Solimo, weight: 50.0, color: Others, height: 2200.0, width: 1879.0, model year: , shape: , style: , material: Canvas, product_type: CELLULAR_PHONE_CASE\n",
      "Metadata: {'category': 'CELLULAR_PHONE_CASE', 'country': 'IN', 'id': 'B07TG4LCWZ', 'image_path': '1f/1fcde4f7.jpg', 'name': 'Amazon Brand - Solimo Designer Multicolor Bin 3D Printed Hard Back Case Mobile Cover for Micromax Canvas Juice 3Plus Q394'}\n",
      "--------------------\n",
      "Document 2: a black and gold phone case for the iphone Given Product description: , None, brand: Amazon Brand - Solimo, weight: 50.0, color: Multicolor, height: 2200.0, width: 1879.0, model year: , shape: , style: , material: Silicone, product_type: CELLULAR_PHONE_CASE\n",
      "Metadata: {'category': 'CELLULAR_PHONE_CASE', 'country': 'IN', 'id': 'B0853WV73C', 'image_path': '2e/2e068dd0.jpg', 'name': 'Amazon Brand - Solimo Designer Golden Butterfly Pattern UV Printed Soft Back Case Mobile Cover for Comio C1'}\n",
      "--------------------\n",
      "Document 3: a purple flower phone case for the iphone Given Product description: , None, brand: Amazon Brand - Solimo, weight: 50.0, color: Others, height: 2200.0, width: 1879.0, model year: , shape: , style: , material: Canvas, product_type: CELLULAR_PHONE_CASE\n",
      "Metadata: {'category': 'CELLULAR_PHONE_CASE', 'country': 'IN', 'id': 'B07TG4RXKP', 'image_path': '1c/1cd24ede.jpg', 'name': 'Amazon Brand - Solimo Designer Purple Flowers 3D Printed Hard Back Case Mobile Cover for Micromax Canvas Selfie 2 Q340'}\n",
      "--------------------\n",
      "Document 4: a purple flower phone case for the iphone Given Product description: , None, brand: Amazon Brand - Solimo, weight: 50.0, color: Multicolor, height: 2200.0, width: 1879.0, model year: , shape: , style: pattern, material: Silicone, product_type: CELLULAR_PHONE_CASE\n",
      "Metadata: {'category': 'CELLULAR_PHONE_CASE', 'country': 'IN', 'id': 'B0853WFS7J', 'image_path': '6a/6aa26c37.jpg', 'name': 'Amazon Brand - Solimo Designer Purple Flowers UV Printed Soft Back Case Mobile Cover for Vivo Y11'}\n",
      "--------------------\n",
      "Document 5: a colorful painting phone case for the iphone Given Product description: , No Warranty, brand: Amazon Brand - Solimo, weight: 50.0, color: Others, height: 2200.0, width: 1879.0, model year: , shape: , style: , material: Canvas, product_type: CELLULAR_PHONE_CASE\n",
      "Metadata: {'category': 'CELLULAR_PHONE_CASE', 'country': 'IN', 'id': 'B07T254LLV', 'image_path': '69/6950a625.jpg', 'name': 'Amazon Brand - Solimo Designer Color Mash On Canvas 3D Printed Hard Back Case Mobile Cover for Micromax Canvas Fire 4 A107'}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Example with k similar results\n",
    "def retrieve_custom_k(query_text, k=5):\n",
    "    #results = vectorstore.similarity_search(query_text, k=k)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    results = retriever.get_relevant_documents(query_text)\n",
    "    return results\n",
    "\n",
    "query = \"Find me a good phone case for IPhone\"\n",
    "results = retrieve_custom_k(query, k=5)\n",
    "\n",
    "if results:\n",
    "    i = 0\n",
    "    for doc in results:\n",
    "        print(f\"Document {i+1}: {doc.page_content}\")\n",
    "        print(f\"Metadata: {doc.metadata}\")\n",
    "        #print(f\"Image: {doc.metadata[\"image_path\"]}\") # debug\n",
    "        #print(f\"Product Type: {doc.metadata[\"category\"]}\") #debug\n",
    "        #print(f\"Country of Origin: {doc.metadata[\"country\"]}\") #debug\n",
    "        print(\"-\" * 20)\n",
    "        i = i+1\n",
    "else:\n",
    "    print(\"No results found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if the API key is loaded correctly\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Generate Natual Language Response using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I found some great options for you! Here are some cool black sneakers for men:\n",
      "\n",
      "1. \"Amazon Brand - Inkast Denim Co. Men's Sneakers\" is the first one on the list. This product falls under the category of 'Shoes' and is manufactured in India. You can check the image here: [0b/0b13da52.jpg](image_path).\n",
      "\n",
      "2. \"Concept 3 by Skechers Men's Xavien Lace-up Sneaker, BBK, 12 Medium US\" also seems to be a great choice. This pair is a product of the USA and belongs to the 'Shoes' category. The product image can be found here: [4b/4b005ffc.jpg](image_path).\n",
      "\n",
      "Please note that the other products listed are either not designed for men or not in black color. Let me know if you need more options or details about these products!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Load an LLM (GPT-4 for best responses, or use an open-source model)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7)\n",
    "\n",
    "def generate_natural_language_response(query, products):\n",
    "    \"\"\"Generate a response based on retrieved products using LLM. Include details like the product category and country where it is made.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    A customer is looking for a product based on this query: \"{query}\"\n",
    "    Here are the recommended products:\n",
    "    {products}\n",
    "    \n",
    "    Generate a natural language response listing the products in a friendly tone.\n",
    "    Include details like the product category and country where it is made.\n",
    "    Embed the image_path from the metadata, if present, in the response at the end.\n",
    "    Format the results as a list.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.predict(prompt)\n",
    "    return response\n",
    "\n",
    "query = \"Recommend me men's sneaker in black color\"\n",
    "recommended_products = retrieve_custom_k(query)\n",
    "\n",
    "# Generate response\n",
    "response_text = generate_natural_language_response(query, recommended_products)\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
